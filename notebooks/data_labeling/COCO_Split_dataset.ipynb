{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport os\nfrom shutil import copy2\n\ndef split_coco_dataset_by_filename(coco_json_path, images_dir, output_dir, test_keyword):\n    \"\"\"\n    按文件名关键字将 COCO 数据集划分为训练集和测试集\n    :param coco_json_path: COCO 标注文件路径\n    :param images_dir: 图片文件夹路径\n    :param output_dir: 输出目录\n    :param test_keyword: 测试集文件名中包含的关键字\n    \"\"\"\n    # 创建输出目录\n    train_images_dir = os.path.join(output_dir, 'train', 'images')\n    test_images_dir = os.path.join(output_dir, 'test', 'images')\n    os.makedirs(train_images_dir, exist_ok=True)\n    os.makedirs(test_images_dir, exist_ok=True)\n\n    # 加载 COCO 标注\n    with open(coco_json_path, 'r') as f:\n        coco_data = json.load(f)\n\n    # 根据文件名关键字划分图片\n    images = coco_data['images']\n    test_images = [img for img in images if test_keyword in img['file_name']]\n    train_images = [img for img in images if test_keyword not in img['file_name']]\n\n    # 更新 COCO 标注\n    def filter_annotations(images_subset):\n        image_ids = {img['id'] for img in images_subset}\n        return [ann for ann in coco_data['annotations'] if ann['image_id'] in image_ids]\n\n    train_annotations = filter_annotations(train_images)\n    test_annotations = filter_annotations(test_images)\n\n    train_coco = {\n        \"images\": train_images,\n        \"annotations\": train_annotations,\n        \"categories\": coco_data['categories']\n    }\n    test_coco = {\n        \"images\": test_images,\n        \"annotations\": test_annotations,\n        \"categories\": coco_data['categories']\n    }\n\n    # 保存新的 COCO 标注文件\n    train_annotations_path = os.path.join(output_dir, 'train', 'annotations.json')\n    test_annotations_path = os.path.join(output_dir, 'test', 'annotations.json')\n    with open(train_annotations_path, 'w') as f:\n        json.dump(train_coco, f, indent=4)\n    with open(test_annotations_path, 'w') as f:\n        json.dump(test_coco, f, indent=4)\n\n    # 复制图片到新目录\n    def copy_images(images_subset, target_dir):\n        for img in images_subset:\n            src_path = os.path.join(images_dir, img['file_name'])\n            dst_path = os.path.join(target_dir, img['file_name'])\n            copy2(src_path, dst_path)\n\n    copy_images(train_images, train_images_dir)\n    copy_images(test_images, test_images_dir)\n\n    print(f\"数据集已成功划分：\")\n    print(f\"训练集图片数：{len(train_images)}，标注数：{len(train_annotations)}\")\n    print(f\"测试集图片数：{len(test_images)}，标注数：{len(test_annotations)}\")\n\nif __name__ == \"__main__\":\n    # TODO: Update these paths to your dataset location\n    coco_json_path = \"./data/raw/augmented_annotations.json\"  # 原始 COCO 格式标注文件路径\n    images_dir = \"./data/raw/\"  # 图片文件夹路径\n    output_dir = \"./data/processed/\"  # 输出目录路径\n\n    # 文件名关键字，用于划分测试集\n    test_keyword = \"62e74158-000006\"\n\n    # 执行分割\n    split_coco_dataset_by_filename(coco_json_path, images_dir, output_dir, test_keyword)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}